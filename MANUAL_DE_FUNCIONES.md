# üìò Manual Completo de Funciones

## Cerebro Artificial - Documentaci√≥n T√©cnica Detallada

---

## √çndice

1. [M√≥dulo AMA-Intent](#ama-intent)
2. [FASE 1: Sistema Perceptivo-Decisional](#fase-1)
3. [FASE 2: Sistema de Memoria](#fase-2)
4. [FASE 3: Sistema de Aprendizaje](#fase-3)
5. [Integraci√≥n y Interfaces](#integracion)
6. [Ejemplos de Uso](#ejemplos)

---

## 1. AMA-Intent - Detector de Intenci√≥n {#ama-intent}

### üìÑ Archivo: `ama_intent.py`

### Clases

#### `Intent`
**Prop√≥sito**: Representaci√≥n inmutable de la intenci√≥n del usuario (I‚ÇÄ)

**Atributos**:
- `raw_text: str` - Texto original
- `intent_hash: str` - Hash SHA-256 de la intenci√≥n
- `request_type: RequestType` - Tipo de solicitud
- `core_goal: str` - Objetivo central extra√≠do
- `key_entities: List[str]` - Entidades clave
- `ambiguity_score: float` - Nivel de ambig√ºedad [0,1]
- `complexity_score: float` - Nivel de complejidad [0,1]
- `timestamp: str` - Marca temporal

**M√©todos**:
```python
def __eq__(self, other: Intent) -> bool
    """Compara dos intenciones por hash"""
```

---

### Funciones Principales

#### `extract_intent(prompt: str, timestamp: Optional[str] = None) -> Intent`

**Prop√≥sito**: Extrae y cristaliza la intenci√≥n original I‚ÇÄ

**Par√°metros**:
- `prompt`: Texto del usuario
- `timestamp`: Marca temporal (opcional)

**Retorna**: Objeto `Intent` inmutable

**Ejemplo**:
```python
from ama_intent import extract_intent

text = "Expl√≠came c√≥mo funciona la fotos√≠ntesis"
I0 = extract_intent(text)

print(I0.request_type)      # RequestType.INFORMATIONAL
print(I0.ambiguity_score)   # 0.15 (bajo)
print(I0.complexity_score)  # 0.45 (medio)
```

---

#### `validate_intent_immutability(I0: Intent, I_current: Intent) -> bool`

**Prop√≥sito**: Verifica que la intenci√≥n no haya sido alterada

**Par√°metros**:
- `I0`: Intenci√≥n original
- `I_current`: Intenci√≥n actual a validar

**Retorna**: `True` si I_current ‚â° I‚ÇÄ

**Ejemplo**:
```python
I0 = extract_intent("Explica la gravedad")
I_response = extract_intent("La gravedad es una fuerza...")

is_preserved = validate_intent_immutability(I0, I_response)
# True si la respuesta mantiene la intenci√≥n
```

---

#### `classify_request_type(prompt: str) -> RequestType`

**Prop√≥sito**: Clasifica el tipo de solicitud

**Tipos**:
- `INFORMATIONAL`: Preguntas sobre hechos
- `ANALYTICAL`: Comparaciones, an√°lisis
- `CREATIVE`: Generaci√≥n de contenido
- `TECHNICAL`: C√≥digo, implementaciones
- `CONVERSATIONAL`: Chat casual
- `INSTRUCTIONAL`: C√≥mo hacer algo
- `SENSITIVE`: Temas m√©dicos, legales

**Ejemplo**:
```python
type1 = classify_request_type("¬øQu√© es Python?")
# RequestType.INFORMATIONAL

type2 = classify_request_type("Escribe un poema")
# RequestType.CREATIVE

type3 = classify_request_type("C√≥mo hacer pan")
# RequestType.INSTRUCTIONAL
```

---

#### `detect_ambiguity(prompt: str) -> float`

**Prop√≥sito**: Calcula score de ambig√ºedad

**Factores evaluados**:
1. Longitud del prompt
2. Pronombres vagos ("esto", "eso")
3. Falta de verbos de acci√≥n
4. Preguntas sin contexto

**Retorna**: Score [0,1] donde 0=claro, 1=muy ambiguo

**Ejemplo**:
```python
ambiguity1 = detect_ambiguity("Explica la teor√≠a de la relatividad de Einstein")
# ~0.15 (bajo)

ambiguity2 = detect_ambiguity("Dime sobre eso")
# ~0.85 (alto)
```

---

#### `calculate_complexity(prompt: str) -> float`

**Prop√≥sito**: Calcula complejidad de la solicitud

**Factores evaluados**:
1. Longitud del texto
2. M√∫ltiples requisitos
3. T√©rminos t√©cnicos
4. Condiciones y restricciones

**Retorna**: Score [0,1] donde 0=simple, 1=muy complejo

**Ejemplo**:
```python
complexity1 = calculate_complexity("¬øQu√© hora es?")
# ~0.05 (muy simple)

complexity2 = calculate_complexity(
    "Implementa un algoritmo de ML que optimice X bajo restricci√≥n Y, 
     considerando Z y validando con m√©tricas A, B y C"
)
# ~0.95 (muy complejo)
```

---

## 2. FASE 1: Sistema Perceptivo-Decisional {#fase-1}

### 2.1 Sensing - Filtro Kalman

#### üìÑ Archivo: `sensing/kalman.py`

#### Clase `ThalamicFilter`

**Prop√≥sito**: Filtro de Kalman para estabilizar observaciones (simula t√°lamo)

**Constructor**:
```python
def __init__(self, 
             dim_state: int, 
             dim_obs: int,
             process_noise: float = 0.01,
             measurement_noise: float = 0.1)
```

**Par√°metros**:
- `dim_state`: Dimensi√≥n del estado latente
- `dim_obs`: Dimensi√≥n de la observaci√≥n
- `process_noise`: Ruido del proceso (Q)
- `measurement_noise`: Ruido de medici√≥n (R)

---

#### `filter(y: np.ndarray) -> Tuple[np.ndarray, Dict]`

**Prop√≥sito**: Filtra observaci√≥n ruidosa

**Ecuaciones**:
```
Predicci√≥n:
  xÃÇ‚Åª‚Çú = F¬∑xÃÇ‚Çú‚Çã‚ÇÅ
  P‚Åª‚Çú = F¬∑P‚Çú‚Çã‚ÇÅ¬∑F·µÄ + Q

Actualizaci√≥n:
  K‚Çú = P‚Åª‚Çú¬∑H·µÄ¬∑(H¬∑P‚Åª‚Çú¬∑H·µÄ + R)‚Åª¬π
  xÃÇ‚Çú = xÃÇ‚Åª‚Çú + K‚Çú¬∑(y‚Çú - H¬∑xÃÇ‚Åª‚Çú)
  P‚Çú = (I - K‚Çú¬∑H)¬∑P‚Åª‚Çú
```

**Retorna**: 
- `y_filtered`: Observaci√≥n filtrada
- `metrics`: M√©tricas del filtro

**Ejemplo**:
```python
from sensing.kalman import ThalamicFilter

thalamus = ThalamicFilter(dim_state=64, dim_obs=384)

# Observaci√≥n ruidosa (embedding)
observation = np.random.randn(384) * 0.5

# Filtrar
y_filtered, metrics = thalamus.filter(observation)

print(metrics['uncertainty'])    # Incertidumbre
print(metrics['innovation_norm'])  # Innovaci√≥n
```

---

### 2.2 Cortex - Atenci√≥n

#### üìÑ Archivo: `cortex/attention.py`

#### Clase `CorticalAttention`

**Prop√≥sito**: Mecanismo de atenci√≥n basado en LSI (√çndice de Sensibilidad Local)

**Constructor**:
```python
def __init__(self, 
             dim: int,
             lambda_init: float = 1.0,
             history_size: int = 100)
```

---

#### `compute_attention(delta: np.ndarray, modulation: Optional[np.ndarray] = None) -> Tuple[np.ndarray, Dict]`

**Prop√≥sito**: Calcula vector de atenci√≥n basado en sorpresa

**Ecuaci√≥n**:
```
LSI(Œ¥‚Çú) = |Œ¥‚Çú| / max(|Œ¥‚Çú|)  (normalizado)
Œ±‚Çú = softmax(Œª¬∑LSI(Œ¥‚Çú))
```

**Par√°metros**:
- `delta`: Error de predicci√≥n (sorpresa)
- `modulation`: Modulaci√≥n externa opcional

**Retorna**:
- `alpha`: Vector de atenci√≥n [0,1]
- `metrics`: M√©tricas de atenci√≥n

**Ejemplo**:
```python
from cortex.attention import CorticalAttention

attention = CorticalAttention(dim=384)

# Error de predicci√≥n
delta = y_filtered - y_predicted

# Calcular atenci√≥n
alpha, metrics = attention.compute_attention(delta)

print(metrics['attention_entropy'])  # Entrop√≠a del foco
print(metrics['focus_index'])        # √çndice de concentraci√≥n
```

---

#### `apply_attention(x: np.ndarray, mode: str = 'modulate') -> np.ndarray`

**Prop√≥sito**: Aplica atenci√≥n a una entrada

**Modos**:
- `'modulate'`: Œ± ‚äô x
- `'gate'`: mask ¬∑ x
- `'soft'`: Œ±^Œ≥ ‚äô x

**Ejemplo**:
```python
# Modular entrada por atenci√≥n
x_attended = attention.apply_attention(x_input, mode='modulate')
```

---

### 2.3 Cortex - Estado Latente

#### üìÑ Archivo: `cortex/state.py`

#### Clase `CorticalState`

**Prop√≥sito**: Mantiene y actualiza estado latente cortical z

**Constructor**:
```python
def __init__(self, config: CorticalStateConfig)
```

---

#### `update(y_hat: np.ndarray, alpha: np.ndarray, w: Optional[np.ndarray] = None) -> Tuple[np.ndarray, Dict]`

**Prop√≥sito**: Actualiza estado cortical

**Ecuaci√≥n**:
```
e‚Çú = œÜ(≈∑‚Çú)                    # Codificaci√≥n
z‚Çú = f(z‚Çú‚Çã‚ÇÅ, Œ±‚Çú‚äôe‚Çú, w‚Çú‚Çã‚ÇÅ)    # Actualizaci√≥n recurrente
```

**Par√°metros**:
- `y_hat`: Observaci√≥n filtrada
- `alpha`: Vector de atenci√≥n
- `w`: Memoria de trabajo (opcional)

**Retorna**:
- `z_new`: Nuevo estado latente
- `metrics`: M√©tricas de actualizaci√≥n

**Ejemplo**:
```python
from cortex.state import create_cortical_state

cortex = create_cortical_state(
    dim_latent=128,
    dim_input=384,
    dim_wm=64
)

z_new, metrics = cortex.update(y_filtered, alpha, w)

print(metrics['z_norm'])      # Norma del estado
print(metrics['z_change'])    # Cambio respecto anterior
print(metrics['sparsity'])    # Sparsity del estado
```

---

#### `predict_next_observation(a: Optional[np.ndarray] = None) -> np.ndarray`

**Prop√≥sito**: Predice siguiente observaci√≥n (modelo del mundo)

**Ecuaci√≥n**:
```
·ªπ‚Çú = g(z‚Çú‚Çã‚ÇÅ, a‚Çú‚Çã‚ÇÅ)
```

**Ejemplo**:
```python
y_predicted = cortex.predict_next_observation()

# Calcular sorpresa
delta, surprise = cortex.compute_surprise(y_actual, y_predicted)
```

---

### 2.4 Decision - Q-Value

#### üìÑ Archivo: `decision/q_value.py`

#### Clase `QValueEstimator`

**Prop√≥sito**: Estima valor Q de acciones con MIEM integrado

**Constructor**:
```python
def __init__(self,
             dim_state: int,
             dim_action: int,
             gamma: float = 0.95,
             risk_aversion: float = 0.5)
```

---

#### `compute_Q(z: np.ndarray, a: np.ndarray, metadata: Optional[Dict] = None, ...) -> Tuple[float, Dict]`

**Prop√≥sito**: Calcula valor Q con MIEM

**Ecuaci√≥n**:
```
Q(z,a) = ùîº[R|z,a] - Coste(a) - œÅ¬∑Riesgo(MIEM)

MIEM = (eficiencia, impacto, modularidad, riesgo)
```

**Par√°metros**:
- `z`: Estado actual
- `a`: Acci√≥n candidata
- `metadata`: Metadatos (complejidad, recursos)
- `environment`: Info del entorno
- `reward_model`: Modelo de recompensa externo

**Retorna**:
- `Q_value`: Valor Q total
- `components`: Desglose de componentes

**Ejemplo**:
```python
from decision.q_value import QValueEstimator

q_est = QValueEstimator(dim_state=128, dim_action=32)

# Evaluar acci√≥n
Q_val, components = q_est.compute_Q(
    z=current_state,
    a=action_candidate,
    metadata={'complexity': 0.5}
)

print(f"Q-value: {Q_val:.3f}")
print(f"Reward: {components['reward']:.3f}")
print(f"Cost: {components['cost']:.3f}")
print(f"Risk: {components['miem_risk']:.3f}")
```

---

### 2.5 Decision - DMD

#### üìÑ Archivo: `decision/dmd.py`

#### Clase `DecisionMatrixDeterministic`

**Prop√≥sito**: Selector de acciones multi-criterio

**Constructor**:
```python
def __init__(self, criteria: Optional[DecisionCriteria] = None)
```

---

#### `decide(action_candidates: List[Dict], constraints: Optional[List[Constraint]] = None, ...) -> DMDResult`

**Prop√≥sito**: Selecciona mejor acci√≥n

**Algoritmo**:
```
1. Filtrar por restricciones HARD
2. Construir matriz de criterios
3. Aplicar ponderaciones
4. Aplicar penalizaciones SOFT
5. Seleccionar m√°ximo score
```

**Par√°metros**:
- `action_candidates`: Lista de candidatos
- `constraints`: Restricciones
- `criteria_override`: Criterios alternativos

**Retorna**: `DMDResult` con acci√≥n seleccionada

**Ejemplo**:
```python
from decision.dmd import DecisionMatrixDeterministic, DecisionCriteria

dmd = DecisionMatrixDeterministic(
    criteria=DecisionCriteria(
        Q_value=1.0,
        efficiency=0.4,
        safety=0.6,
        modularity=0.2
    )
)

result = dmd.decide(
    action_candidates=candidates,
    constraints=[safety_constraint]
)

print(f"Selected: {result.selected_action_id}")
print(f"Score: {result.score:.3f}")
```

---

### 2.6 Governance - AMA-G

#### üìÑ Archivo: `governance/amag_audit.py`

#### Clase `AMAGAuditor`

**Prop√≥sito**: Auditor√≠a y gobernanza (PFC metacognitivo)

**Constructor**:
```python
def __init__(self, thresholds: Optional[GovernanceThresholds] = None)
```

---

#### `audit(z: np.ndarray, w: Optional[np.ndarray], R: Optional[List], action_candidate: Dict, surprise: float, ...) -> AuditReport`

**Prop√≥sito**: Audita sistema completo

**Verificaciones**:
1. Sorpresa excesiva
2. Incertidumbre alta
3. Riesgo elevado
4. Consistencia interna
5. Magnitud de acci√≥n

**Ecuaci√≥n de confianza**:
```
confidence = 0.3¬∑(1-surprise_norm) + 0.3¬∑safety + 
             0.3¬∑consistency + 0.1¬∑magnitude_ok
```

**Retorna**: `AuditReport` con resultado y recomendaciones

**Ejemplo**:
```python
from governance.amag_audit import AMAGAuditor, GovernanceThresholds

auditor = AMAGAuditor(
    thresholds=GovernanceThresholds(
        min_confidence=0.5,
        max_surprise=3.0,
        max_risk=0.7
    )
)

report = auditor.audit(
    z=state,
    w=working_memory,
    R=episodes,
    action_candidate=selected_action,
    surprise=surprise_value
)

if report.result == AuditResult.PASS:
    execute(report.selected_action)
elif report.result == AuditResult.REVISED:
    execute(report.revised_action)
else:
    execute(report.safe_action)
```

---

## 3. FASE 2: Sistema de Memoria {#fase-2}

### 3.1 Memoria Epis√≥dica

#### üìÑ Archivo: `memory/episodic_graph.py`

#### Clase `EpisodicMemoryGraph`

**Prop√≥sito**: Memoria epis√≥dica como grafo con PageRank

**Constructor**:
```python
def __init__(self, 
             max_episodes: int = 10000,
             similarity_threshold: float = 0.7)
```

---

#### `add_episode(state: np.ndarray, context: Dict, tags: Optional[Set[str]] = None, ...) -> str`

**Prop√≥sito**: A√±ade episodio a memoria

**Conexiones creadas**:
- Temporal (episodios consecutivos)
- Similaridad (estados similares)
- Causal (mismo tag/contexto)

**Retorna**: ID del episodio

**Ejemplo**:
```python
from memory.episodic_graph import EpisodicMemoryGraph

memory = EpisodicMemoryGraph(max_episodes=5000)

episode_id = memory.add_episode(
    state=z_current,
    context={'action': 'explore', 'reward': 0.8},
    tags={'navigation', 'success'},
    importance=0.9
)
```

---

#### `retrieve(query_state: np.ndarray, top_k: int = 5, use_pagerank: bool = True, ...) -> List[Tuple]`

**Prop√≥sito**: Recupera episodios relevantes

**Score compuesto**:
```
Score(v) = w_sim¬∑sim(z,v) + w_pr¬∑PageRank(v) + 
           w_lfpi¬∑LFPI(v) + w_lsi¬∑LSI(v)
```

**Retorna**: Lista de (episode_id, score, episode)

**Ejemplo**:
```python
# Recuperar 5 episodios m√°s relevantes
results = memory.retrieve(
    query_state=current_state,
    top_k=5,
    use_pagerank=True
)

for ep_id, score, episode in results:
    print(f"{ep_id}: score={score:.3f}")
    print(f"  Context: {episode.context}")
```

---

#### `compute_pagerank(damping: float = 0.85, ...) -> Dict[str, float]`

**Prop√≥sito**: Calcula PageRank para episodios

**Ecuaci√≥n**:
```
PR(v) = (1-d)/N + d¬∑Œ£ PR(u)/|Out(u)|
```

**Retorna**: Dict de scores por episodio

---

### 3.2 Memoria Sem√°ntica

#### üìÑ Archivo: `memory/semantic_matrix.py`

#### Clase `SemanticMemoryMatrix`

**Prop√≥sito**: Memoria sem√°ntica (conceptos abstractos)

**Constructor**:
```python
def __init__(self,
             dim_state: int,
             max_concepts: int = 1000,
             learning_rate: float = 0.01,
             compression_dim: Optional[int] = None)
```

---

#### `consolidate(state: np.ndarray, tags: Optional[List[str]] = None, threshold: float = 0.8) -> Tuple[int, bool]`

**Prop√≥sito**: Consolida estado en memoria

**Estrategia**:
```
Si existe concepto similar ‚Üí actualizar prototipo
Si no existe ‚Üí crear nuevo concepto
```

**Actualizaci√≥n**:
```
nuevo_prototipo = (1-Œ±)¬∑viejo + Œ±¬∑nuevo
```

**Retorna**: (concept_id, is_new)

**Ejemplo**:
```python
from memory.semantic_matrix import SemanticMemoryMatrix

semantic = SemanticMemoryMatrix(
    dim_state=128,
    max_concepts=500,
    learning_rate=0.05
)

concept_id, is_new = semantic.consolidate(
    state=z_current,
    tags=['mathematics', 'algebra'],
    threshold=0.8
)

if is_new:
    print(f"Nuevo concepto creado: {concept_id}")
else:
    print(f"Concepto actualizado: {concept_id}")
```

---

#### `retrieve(query: np.ndarray, top_k: int = 5, min_similarity: float = 0.5) -> List[Tuple]`

**Prop√≥sito**: Recupera conceptos relevantes

**Retorna**: Lista de (concept_id, similarity, concept)

---

#### `merge_similar_concepts(threshold: float = 0.95)`

**Prop√≥sito**: Fusiona conceptos muy similares

**Ejemplo**:
```python
# Fusionar conceptos con similaridad > 0.95
semantic.merge_similar_concepts(threshold=0.95)
```

---

### 3.3 Working Memory

#### üìÑ Archivo: `memory/working_memory.py`

#### Clase `WorkingMemory`

**Prop√≥sito**: Memoria de trabajo con gating (PFC)

**Constructor**:
```python
def __init__(self, 
             dim: int,
             config: Optional[WorkingMemoryConfig] = None)
```

---

#### `update(z: np.ndarray, retrieved_episodes: Optional[List] = None, ...) -> Tuple[np.ndarray, Dict]`

**Prop√≥sito**: Actualiza working memory con gating

**Ecuaci√≥n**:
```
gate = œÉ(Œì[z‚Çú, w‚Çú‚Çã‚ÇÅ])
w‚Çú = gate‚äôw‚Çú‚Çã‚ÇÅ + (1-gate)‚äônew_content
```

**Par√°metros**:
- `z`: Estado cortical
- `retrieved_episodes`: Episodios recuperados
- `task_relevance`: Relevancia de tarea

**Retorna**: (w_new, metrics)

**Ejemplo**:
```python
from memory.working_memory import WorkingMemory

wm = WorkingMemory(dim=64)

w_new, metrics = wm.update(
    z=current_state,
    retrieved_episodes=episodes
)

print(f"Active slots: {metrics['active_slots']}")
print(f"Gate mean: {metrics['gate_mean']:.3f}")
```

---

#### `rehearse(iterations: int = 5, strength: float = 0.9)`

**Prop√≥sito**: Rehearsal para mantener informaci√≥n

**Ejemplo**:
```python
# Reforzar contenido actual
wm.rehearse(iterations=5)
```

---

### 3.4 Sistema de Poda

#### üìÑ Archivo: `memory/pruning.py`

#### Clase `AdaptivePruningSystem`

**Prop√≥sito**: Olvido selectivo adaptativo

**Constructor**:
```python
def __init__(self, config: Optional[PruningConfig] = None)
```

---

#### `select_candidates(items: List[MemoryItem], n_to_prune: Optional[int] = None) -> List[str]`

**Prop√≥sito**: Selecciona items a podar

**Criterios**:
```
Score = w_recency¬∑(1-recency) + 
        w_frequency¬∑frequency + 
        w_impact¬∑impact
```

**Poda si**:
```
uso(x) < u_min ‚àß impacto(x) < Œπ_min
```

**Retorna**: Lista de IDs a podar

**Ejemplo**:
```python
from memory.pruning import AdaptivePruningSystem

pruner = AdaptivePruningSystem()

# Ejecutar poda
prune_stats = pruner.execute_pruning(
    episodic_memory,
    semantic_memory,
    force=False
)

print(f"Items podados: {prune_stats['pruned_count']}")
```

---

## 4. FASE 3: Sistema de Aprendizaje {#fase-3}

### 4.1 Control PID Homeost√°tico

#### üìÑ Archivo: `control/pid_homeostasis.py`

#### Clase `HomeostaticSystem`

**Prop√≥sito**: Control homeost√°tico multi-PID (cerebelo)

**Constructor**:
```python
def __init__(self)
```

**Controladores**:
1. **Exploraci√≥n œÑ**: Balance exploraci√≥n-explotaci√≥n
2. **Learning rate Œ∑**: Velocidad de aprendizaje
3. **Atenci√≥n Œª**: Concentraci√≥n del foco
4. **Gating**: Umbral de actualizaci√≥n WM
5. **Risk aversion œÅ**: Tolerancia al riesgo

---

#### `update_all(surprise: float, stability: float, attention_focus: float, wm_load: float, performance: float) -> Dict`

**Prop√≥sito**: Actualiza todos los controladores

**Ecuaci√≥n PID**:
```
u(t) = Kp¬∑e(t) + Ki¬∑‚à´e(œÑ)dœÑ + Kd¬∑de(t)/dt
```

**Retorna**: Dict con par√°metros actualizados

**Ejemplo**:
```python
from control.pid_homeostasis import HomeostaticSystem

homeostasis = HomeostaticSystem()

params = homeostasis.update_all(
    surprise=1.2,
    stability=0.7,
    attention_focus=0.6,
    wm_load=0.5,
    performance=0.75
)

# Aplicar par√°metros
exploration_tau = params[ControlledParameter.EXPLORATION]
learning_rate = params[ControlledParameter.LEARNING_RATE]
```

---

#### `adapt_to_context(context: str)`

**Prop√≥sito**: Adapta setpoints seg√∫n contexto

**Contextos**:
- `'learning'`: Alta exploraci√≥n, alta LR
- `'exploitation'`: Baja exploraci√≥n, baja LR
- `'exploration'`: M√°xima exploraci√≥n
- `'emergency'`: Modo seguro

**Ejemplo**:
```python
# Cambiar a modo aprendizaje
homeostasis.adapt_to_context('learning')
```

---

### 4.2 Funci√≥n de P√©rdida

#### üìÑ Archivo: `learning/loss.py`

#### Clase `CompositeLoss`

**Prop√≥sito**: Funci√≥n de p√©rdida compuesta

**Constructor**:
```python
def __init__(self, weights: Optional[LossWeights] = None)
```

---

#### `compute_total_loss(prediction_metrics: Dict, memory_metrics: Dict, policy_metrics: Dict, governance_metrics: Dict) -> Tuple[float, Dict]`

**Prop√≥sito**: Calcula p√©rdida total

**Ecuaci√≥n**:
```
‚Ñí‚Çú = w‚ÇÅ¬∑‚Ñípred + w‚ÇÇ¬∑‚Ñímem + w‚ÇÉ¬∑‚Ñípol + w‚ÇÑ¬∑‚Ñígov
```

**Componentes**:
- **‚Ñípred**: Error de predicci√≥n
- **‚Ñímem**: P√©rdida de memoria
- **‚Ñípol**: P√©rdida de pol√≠tica
- **‚Ñígov**: P√©rdida de gobernanza

**Retorna**: (total_loss, components)

**Ejemplo**:
```python
from learning.loss import CompositeLoss

loss_fn = CompositeLoss()

total_loss, components = loss_fn.compute_total_loss(
    prediction_metrics={'y_predicted': y_pred, 'y_actual': y_act},
    memory_metrics={'retrieval_accuracy': 0.8, 'consolidation_rate': 0.95}
)
```

---

## 7. Conclusi√≥n T√©cnica

El sistema **AMA-Intent** representa una arquitectura de vanguardia en el campo de la IA biomim√©tica. A trav√©s de la integraci√≥n de componentes como el **Long Horizon Agent** y el optimizador **MuonClip**, el sistema no solo emula el razonamiento humano, sino que lo potencia con una estabilidad y eficiencia computacional superiores.

La modularidad del sistema, dividida en fases perceptivas, de memoria y de aprendizaje, permite una evoluci√≥n continua del conocimiento (I‚ÇÄ) sin comprometer la integridad de la intenci√≥n original del usuario. Esta documentaci√≥n sirve como gu√≠a base para desarrolladores que deseen extender las capacidades del cerebro artificial o integrar nuevos motores de decisi√≥n.

---
**Fin del Manual de Funciones**
