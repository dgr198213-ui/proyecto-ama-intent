"""
Ejemplos de Uso - Integraci√≥n Kimi K2 en AMA-Intent

Este archivo contiene ejemplos pr√°cticos de c√≥mo usar cada componente
de la integraci√≥n Kimi K2 en el sistema AMA-Intent.
"""

import asyncio
import torch
import torch.nn as nn
from pathlib import Path


# ============================================================================
# Ejemplo 1: MuonClip Optimizer - Entrenamiento Estable
# ============================================================================

def example_muonclip_training():
    """
    Ejemplo de entrenamiento de un Reward Model usando MuonClip
    para prevenir loss spikes
    """
    print("\n" + "="*60)
    print("Ejemplo 1: MuonClip Optimizer")
    print("="*60)
    
    from training.optimizers import MuonClipOptimizer, MuonClipConfig
    
    # Modelo simple de ejemplo
    class SimpleRewardModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.fc1 = nn.Linear(512, 256)
            self.fc2 = nn.Linear(256, 1)
        
        def forward(self, x):
            x = torch.relu(self.fc1(x))
            return self.fc2(x)
    
    # Configuraci√≥n del optimizador
    config = MuonClipConfig(
        learning_rate=1e-4,
        tau=100.0,              # Umbral de saturaci√≥n de logits
        eta=0.95,               # Factor de atenuaci√≥n
        qk_clip_enabled=True,   # Habilitar QK-Clip
        early_stop_on_spike=True,
        spike_threshold=5.0
    )
    
    # Crear modelo y optimizador
    model = SimpleRewardModel()
    optimizer = MuonClipOptimizer(model, config)
    
    # Simular entrenamiento
    print("\nüöÄ Iniciando entrenamiento con MuonClip...")
    for step in range(10):
        # Datos sint√©ticos
        x = torch.randn(8, 512)
        target = torch.randn(8, 1)
        
        # Forward pass
        output = model(x)
        loss = nn.MSELoss()(output, target)
        
        # Backward y step con monitoreo
        optimizer.zero_grad()
        stats = optimizer.step_with_monitoring(loss)
        
        if step % 5 == 0:
            print(f"Step {stats.step}: Loss={stats.loss:.4f}, "
                  f"GradNorm={stats.gradient_norm:.4f}, "
                  f"QK Clips={stats.qk_clips_triggered}")
    
    print("‚úÖ Entrenamiento completado sin loss spikes")


# ============================================================================
# Ejemplo 2: Long Horizon Agent - Tarea de 300 Pasos
# ============================================================================

async def example_long_horizon_agent():
    """
    Ejemplo de uso del Long Horizon Agent para una tarea compleja
    """
    print("\n" + "="*60)
    print("Ejemplo 2: Long Horizon Agent")
    print("="*60)
    
    from agents.long_horizon import LongHorizonAgent
    
    # Nota: En producci√≥n, usar LLMHub real
    class MockLLMHub:
        async def generate(self, prompt):
            return "An√°lisis completado"
    
    # Inicializar agente
    llm_hub = MockLLMHub()
    agent = LongHorizonAgent(
        llm_hub=llm_hub,
        kg=None,  # Knowledge Graph opcional
        dmd=None,  # Decision Matrix opcional
        auditor=None  # Auditor opcional
    )
    
    # Ejecutar tarea de largo horizonte
    print("\nüöÄ Ejecutando tarea compleja de 50 pasos...")
    result = await agent.execute_long_task(
        user_goal="Analizar proyecto completo y generar informe de calidad",
        max_steps=50,
        checkpoint_interval=10
    )
    
    print(f"\n‚úÖ Tarea completada:")
    print(f"  ‚Ä¢ Pasos totales: {result.get('total_steps', 'N/A')}")
    print(f"  ‚Ä¢ Tasa de √©xito: {result.get('success_rate', 0)*100:.1f}%")
    print(f"  ‚Ä¢ Goal drift detectado: {result.get('goal_drift_detected', False)}")


# ============================================================================
# Ejemplo 3: Agentic Data Synthesizer - Generaci√≥n de Trayectorias
# ============================================================================

async def example_data_synthesizer():
    """
    Ejemplo de generaci√≥n de trayectorias sint√©ticas para entrenar
    Reward Models usando RLVR
    """
    print("\n" + "="*60)
    print("Ejemplo 3: Agentic Data Synthesizer")
    print("="*60)
    
    from ama_data.synthesis import AgenticDataSynthesizer, BugType
    
    # Nota: En producci√≥n, usar LLMHub real
    class MockLLMHub:
        async def generate(self, prompt):
            return "def fixed_function(): pass"
    
    # Inicializar synthesizer
    llm_hub = MockLLMHub()
    synthesizer = AgenticDataSynthesizer(llm_hub=llm_hub, kg=None)
    
    # Generar trayectorias sint√©ticas
    print("\nüöÄ Generando trayectorias sint√©ticas...")
    trajectories = await synthesizer.generate_trajectories(
        num_trajectories=10,
        variants_per_bug=3
    )
    
    print(f"\n‚úÖ Generadas {len(trajectories)} trayectorias")
    
    # Convertir a pares de preferencias
    pairs = synthesizer.convert_to_preference_pairs(trajectories)
    print(f"‚úÖ Creados {len(pairs)} pares de preferencias")
    
    # Guardar dataset
    output_path = Path("/tmp/preference_dataset.json")
    synthesizer.save_dataset(pairs, output_path)
    print(f"‚úÖ Dataset guardado en: {output_path}")


# ============================================================================
# Ejemplo 4: Context Caching + MLA - Reducci√≥n de Costos
# ============================================================================

def example_context_caching():
    """
    Ejemplo de uso de Context Caching para reducir costos de LLM
    """
    print("\n" + "="*60)
    print("Ejemplo 4: Context Caching + MLA")
    print("="*60)
    
    from llm.connector import ContextCache, MultiHeadLatentAttention
    
    # Inicializar cache
    cache = ContextCache(max_cache_size=100, ttl_hours=24)
    
    # Prefijo com√∫n (system prompt + contexto est√°tico)
    common_prefix = """
    Eres un asistente de c√≥digo experto.
    Conoces Python, JavaScript y arquitecturas de software.
    Tu objetivo es ayudar a analizar y mejorar c√≥digo.
    """
    
    print("\nüöÄ Simulando queries con caching...")
    
    # Primera query (MISS)
    cached = cache.get(common_prefix)
    if cached is None:
        print("‚ùå Cache MISS - Procesando prefijo completo")
        cache.put(common_prefix, token_count=1000)
    
    # Segunda query (HIT)
    cached = cache.get(common_prefix)
    if cached is not None:
        print("‚úÖ Cache HIT - Ahorro de 1000 tokens")
    
    # Estad√≠sticas
    stats = cache.get_stats()
    print(f"\nüìä Estad√≠sticas del cache:")
    print(f"  ‚Ä¢ Hit Rate: {stats['hit_rate']*100:.1f}%")
    print(f"  ‚Ä¢ Tokens ahorrados: {stats['tokens_saved']:,}")
    print(f"  ‚Ä¢ Costo ahorrado: ${stats['cost_saved_usd']:.4f}")
    
    # MLA Attention
    print("\nüß† Multi-Head Latent Attention:")
    mla = MultiHeadLatentAttention(
        d_model=512,
        num_heads=8,
        latent_dim=128  # Compresi√≥n 4x
    )
    
    # Simular atenci√≥n sobre contexto largo
    batch_size = 2
    seq_len = 1000  # 1000 tokens
    x = torch.randn(batch_size, seq_len, 512)
    
    output, metadata = mla(x, x, x)
    
    print(f"  ‚Ä¢ Compresi√≥n KV: {metadata['compression_ratio']:.1f}x")
    print(f"  ‚Ä¢ Memoria ahorrada: {metadata['memory_saved_elements']:,} elementos")
    print(f"  ‚Ä¢ Cache usado: {metadata['cache_used']}")


# ============================================================================
# Ejecutar Todos los Ejemplos
# ============================================================================

def main():
    """Ejecuta todos los ejemplos"""
    print("\n" + "="*60)
    print("AMA-Intent - Ejemplos de Integraci√≥n Kimi K2")
    print("="*60)
    
    # Ejemplo 1: MuonClip (s√≠ncrono)
    example_muonclip_training()
    
    # Ejemplo 4: Context Caching (s√≠ncrono)
    example_context_caching()
    
    # Ejemplos as√≠ncronos
    print("\nüîÑ Ejecutando ejemplos as√≠ncronos...")
    asyncio.run(example_long_horizon_agent())
    asyncio.run(example_data_synthesizer())
    
    print("\n" + "="*60)
    print("‚úÖ Todos los ejemplos completados exitosamente")
    print("="*60)


if __name__ == "__main__":
    main()
