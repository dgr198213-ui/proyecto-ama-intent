import os
import subprocess
import sys

from dotenv import load_dotenv


def main():
    # Cargar variables de entorno
    load_dotenv()
    print("ğŸ§  Iniciando Protocolo AMA-Intent v3...")

    # Verificar que existe la carpeta data
    if not os.path.exists("data"):
        os.makedirs("data")
        print("ğŸ“ Carpeta de memoria creada.")

    # Verificar Ollama (soluciÃ³n pragmÃ¡tica)
    try:
        result = subprocess.run(
            ["ollama", "list"], capture_output=True, text=True, check=False
        )
        if result.returncode != 0:
            print("âŒ ERROR: Ollama no parece estar instalado o corriendo.")
            print("ğŸ‘‰ Ejecuta 'ollama serve' en otra terminal.")
            sys.exit(1)

        # Verificar si el modelo especÃ­fico estÃ¡ descargado
        model = os.getenv("OLLAMA_MODEL", "llama3.1")
        if model not in result.stdout:
            print(f"âš ï¸ ADVERTENCIA: El modelo '{model}' no se encuentra en Ollama.")
            print(f"ğŸ‘‰ Intenta descargarlo con: ollama pull {model}")
            # No salimos, tal vez 'ollama list' no mostrÃ³ todo o el usuario sabe lo que hace
            # Pero damos el aviso claro
        else:
            print(f"âœ… Modelo '{model}' verificado.")

    except FileNotFoundError:
        print("âŒ ERROR: Ollama no estÃ¡ instalado.")
        print("ğŸ‘‰ Instala Ollama desde https://ollama.ai")
        sys.exit(1)

    # Lanzar puente
    print("ğŸš€ Levantando el puente neuronal en puerto 5001...")
    try:
        subprocess.run([sys.executable, "-m", "bridge.server"], check=True)
    except KeyboardInterrupt:
        print("\nâœ… Sistema detenido correctamente.")
    except Exception as e:
        print(f"âŒ Error al iniciar el servidor: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
