# ğŸ—ï¸ AMA-Intent v3 Architecture Diagram

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AMA-Intent v3 System                         â”‚
â”‚                  Biomimetic Intelligence System                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ User runs
                              â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  start.py    â”‚
                      â”‚  (Launcher)  â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                           â”‚
                â–¼                           â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Verify      â”‚           â”‚ Start Server    â”‚
        â”‚ Ollama      â”‚           â”‚ (bridge)        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                           â”‚
                    â”‚        bridge/server.py                   â”‚
                    â”‚        FastHTML Application               â”‚
                    â”‚                                           â”‚
                    â”‚  GET  / â”€â”€â”€â”€â”€â”€â”€â”€â–º Web Interface           â”‚
                    â”‚  GET  /admin â”€â”€â”€â–º Admin Dashboard         â”‚
                    â”‚  GET  /credenciales â–º Credentials Panel   â”‚
                    â”‚                                           â”‚
                    â”‚  POST /api/synapse â”€â–º Process Request     â”‚
                    â”‚                                           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚                         â”‚
                           â–¼                         â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ local_cortex/    â”‚    â”‚ local_cortex/    â”‚
                  â”‚ thought.py       â”‚    â”‚ memory.py        â”‚
                  â”‚                  â”‚    â”‚                  â”‚
                  â”‚ LocalBrain       â”‚    â”‚ SQLite DB        â”‚
                  â”‚ â”œâ”€ think()       â”‚    â”‚ â”œâ”€ init_db()    â”‚
                  â”‚ â””â”€ fast_classifyâ”‚    â”‚ â”œâ”€ save_thought()â”‚
                  â”‚                  â”‚    â”‚ â””â”€ get_last...() â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚                        â”‚
                           â”‚                        â”‚
                           â–¼                        â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Ollama          â”‚      â”‚ data/           â”‚
                  â”‚ (Llama 3.1)     â”‚      â”‚ ama_memory.db   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Details

### 1. Entry Point: `start.py`
**Purpose**: System launcher and health checker
- Checks Ollama availability
- Creates data directory if needed
- Launches the bridge server
- Handles graceful shutdown

### 2. Bridge Layer: `bridge/server.py`
**Purpose**: HTTP API for external communication
- **GET /**: Web interface showing system status
- **POST /api/synapse**: Main processing endpoint
  - Receives user input
  - Coordinates with brain and memory
  - Returns structured response

### 3. Brain Layer: `local_cortex/thought.py`
**Purpose**: AI processing and classification
- **LocalBrain class**:
  - `think()`: Processes user input with context
  - `fast_classify()`: Quick intent classification
- Uses Ollama for LLM inference
- System prompt defines biomimetic behavior

### 4. Memory Layer: `local_cortex/memory.py`
**Purpose**: Persistent storage and retrieval
- **Database**: SQLite (lightweight, serverless)
- **Functions**:
  - `init_db()`: Creates schema
  - `save_thought()`: Stores interactions
  - `get_last_thoughts()`: Context retrieval
- Uses context managers for safe transactions

## Data Flow

### Processing a Request

```
1. Client Request
   POST /api/synapse
   { "input": "What is Python?" }
        â”‚
        â–¼
2. Bridge receives request
   bridge/server.py::synapse()
        â”‚
        â”œâ”€â–º Get context from memory
        â”‚   memory.get_last_thoughts()
        â”‚
        â”œâ”€â–º Classify intent
        â”‚   brain.fast_classify()
        â”‚
        â”œâ”€â–º Process with LLM
        â”‚   brain.think()
        â”‚
        â””â”€â–º Save to memory
            memory.save_thought()
        â”‚
        â–¼
3. Client Response
   {
     "status": "success",
     "intent": "CHAT",
     "response": "Python is...",
     "timestamp": "2026-01-23T..."
   }
```

## File Structure

```
proyecto-ama-intent/
â”‚
â”œâ”€â”€ start.py                    # ğŸš€ Entry point
â”‚
â”œâ”€â”€ bridge/                     # ğŸŒ‰ HTTP Layer
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ server.py              # FastHTML app, /api/synapse endpoint
â”‚
â”œâ”€â”€ local_cortex/              # ğŸ§  Intelligence Layer
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ thought.py             # LocalBrain class, LLM processing
â”‚   â””â”€â”€ memory.py              # SQLite operations
â”‚
â”œâ”€â”€ data/                      # ğŸ’¾ Persistence Layer
â”‚   â””â”€â”€ ama_memory.db         # SQLite database (auto-created)
â”‚
â”œâ”€â”€ requirements.txt           # ğŸ“¦ Dependencies (4 only)
â”œâ”€â”€ .env.example              # âš™ï¸ Configuration template
â”œâ”€â”€ .gitignore                # ğŸš« Exclude patterns
â”œâ”€â”€ .flake8                   # ğŸ“ Linting config
â”œâ”€â”€ README.md                 # ğŸ“– User documentation
â”œâ”€â”€ REFACTORING_SUMMARY.md    # ğŸ“Š v2â†’v3 comparison
â”œâ”€â”€ ARCHITECTURE_DIAGRAM.md   # ğŸ—ï¸ This file
â””â”€â”€ test_ama_v3.py           # ğŸ§ª Test suite
```

## Configuration

### Environment Variables (.env)
```bash
HOST=127.0.0.1      # Server binding (localhost for security)
PORT=5001           # Server port
RELOAD=false        # Auto-reload (dev only)
OLLAMA_MODEL=llama3.1  # LLM model to use
```

## Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Server** | FastHTML + Uvicorn | Lightweight async HTTP |
| **Brain** | Ollama (Llama 3.1) | Local LLM inference |
| **Memory** | SQLite | Embedded database |
| **Config** | python-dotenv | Environment management |

## Design Principles

### 1. Biomimetic Architecture
- **Brain** (local_cortex): Processes and thinks
- **Memory** (data): Stores and recalls
- **Bridge** (HTTP): Communicates with outside world

### 2. Local-First
- No cloud dependencies
- All processing happens locally
- Data stays on your machine

### 3. Simplicity
- 4 dependencies only
- ~200 lines of core code
- No complex abstractions

### 4. Security
- Localhost binding by default
- Context managers for safety
- No secrets in code
- Subprocess isolation

### 5. Maintainability
- Clear separation of concerns
- Comprehensive tests
- Type hints and documentation
- Consistent code style

## Scalability Considerations

### Current (v3)
- Single-threaded server
- Local SQLite database
- One model at a time

### Future Enhancements
- Multi-model support
- Concurrent request handling
- Remote deployment option
- Plugin architecture
- Multi-user support

---

**Note**: This architecture prioritizes simplicity and local operation. 
For production deployments with high concurrency needs, consider:
- Using a connection pool for SQLite
- Adding Redis for session management
- Implementing request queuing
- Containerizing with Docker
