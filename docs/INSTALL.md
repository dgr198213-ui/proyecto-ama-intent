# ğŸ Cerebro Artificial - Paquete Final

## GuÃ­a Completa de DistribuciÃ³n y Uso

---

## ğŸ“¦ Contenido del Paquete

Este paquete incluye un **sistema completo de IA local gobernada** con arquitectura biomimÃ©tica.

### Archivos Incluidos (20 mÃ³dulos)

```
cerebro_artificial/
â”‚
â”œâ”€â”€ ğŸ“„ install.py              # Instalador automatizado
â”œâ”€â”€ ğŸ“„ start.py                # Launcher principal
â”œâ”€â”€ ğŸ“„ README.md               # DocumentaciÃ³n bÃ¡sica
â”‚
â”œâ”€â”€ ğŸ§  MÃ“DULOS DEL CEREBRO (FASE 1+2+3)
â”‚
â”œâ”€â”€ sensing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ kalman.py              # âœ… Filtro Kalman (TÃ¡lamo)
â”‚
â”œâ”€â”€ cortex/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ attention.py           # âœ… AtenciÃ³n LSI
â”‚   â””â”€â”€ state.py               # âœ… Estado latente
â”‚
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ episodic_graph.py      # âœ… Memoria episÃ³dica (PageRank)
â”‚   â”œâ”€â”€ semantic_matrix.py     # âœ… Memoria semÃ¡ntica
â”‚   â”œâ”€â”€ working_memory.py      # âœ… Working memory (PFC)
â”‚   â””â”€â”€ pruning.py             # âœ… Sistema de poda
â”‚
â”œâ”€â”€ decision/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ q_value.py             # âœ… Q-Value (MIEM)
â”‚   â””â”€â”€ dmd.py                 # âœ… DecisiÃ³n matricial
â”‚
â”œâ”€â”€ governance/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ amag_audit.py          # âœ… Auditor AMA-G
â”‚
â”œâ”€â”€ control/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ pid_homeostasis.py     # âœ… Control PID homeostÃ¡tico
â”‚
â”œâ”€â”€ learning/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loss.py                # âœ… FunciÃ³n de pÃ©rdida
â”‚   â”œâ”€â”€ stability.py           # âœ… Control de estabilidad
â”‚   â””â”€â”€ consolidation.py       # âœ… Ciclo de sueÃ±o
â”‚
â”œâ”€â”€ ğŸ”— INTEGRACIÃ“N
â”‚
â”œâ”€â”€ ama_intent.py              # âœ… Extractor de intenciÃ³n
â”œâ”€â”€ brain_complete.py          # âœ… Cerebro integrado
â”œâ”€â”€ ollama_brain_interface.py # âœ… Interfaz con Ollama/LM Studio
â”‚
â”œâ”€â”€ ğŸ–¥ï¸ INTERFACES
â”‚
â”œâ”€â”€ cli_interactive.py         # âœ… CLI interactiva
â””â”€â”€ brain_gui.py               # âœ… GUI moderna
```

---

## ğŸš€ InstalaciÃ³n en 3 Pasos

### Paso 1: Instalar Ollama

**Windows:**
```powershell
# Descargar instalador desde https://ollama.ai
# Ejecutar instalador
# Verificar
ollama --version
```

**macOS:**
```bash
# Descargar desde https://ollama.ai
# O usar Homebrew:
brew install ollama

# Verificar
ollama --version
```

**Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh

# Verificar
ollama --version
```

### Paso 2: Descargar Modelo

```bash
# Modelo recomendado (2GB)
ollama pull gemma2:2b

# Alternativas:
# ollama pull qwen2.5:3b    (3GB, mÃ¡s potente)
# ollama pull llama3.2:3b   (3GB, muy bueno)
# ollama pull mistral:7b    (7GB, mÃ¡xima calidad)
```

### Paso 3: Instalar Cerebro

```bash
# Navegar al directorio del proyecto
cd cerebro_artificial

# Ejecutar instalador
python install.py

# Seguir instrucciones en pantalla
```

El instalador se encarga automÃ¡ticamente de:
- âœ… Verificar Python
- âœ… Comprobar Ollama
- âœ… Instalar dependencias
- âœ… Crear estructura
- âœ… Configurar sistema

---

## ğŸ® Uso del Sistema

### OpciÃ³n 1: Interfaz GrÃ¡fica (Recomendado)

```bash
python start.py --gui
```

**CaracterÃ­sticas de la GUI:**
- ğŸ’¬ Chat en tiempo real
- ğŸ“Š MÃ©tricas en vivo
- ğŸ§  Estado del cerebro
- ğŸ“ Log de eventos
- âš™ï¸ Controles avanzados

![GUI Screenshot](https://via.placeholder.com/800x600?text=GUI+del+Cerebro+Artificial)

### OpciÃ³n 2: Terminal (CLI)

```bash
python start.py --cli
```

**Comandos disponibles:**
```
/help      - Muestra ayuda
/stats     - EstadÃ­sticas del sistema
/config    - ConfiguraciÃ³n actual
/sleep     - Fuerza consolidaciÃ³n
/history   - Historial de conversaciÃ³n
/export    - Exporta a JSON
/exit      - Salir
```

### OpciÃ³n 3: Auto-detectar

```bash
python start.py
```

El sistema intentarÃ¡ GUI primero, si no estÃ¡ disponible usarÃ¡ CLI.

---

## ğŸ’¡ Ejemplos de Uso

### ConversaciÃ³n BÃ¡sica

```
ğŸ§‘ TÃº: Â¿QuÃ© es la inteligencia artificial?

[Sistema procesa...]
[AMA-Intent] Extrayendo intenciÃ³n...
[AMA-G Fase 1] Evaluando entrada... âœ“
[Shadow Prompt] Generando contexto...
[Ollama] Generando respuesta...
[AMA-G Fase 3] Validando respuesta... âœ“
[ConsolidaciÃ³n] Almacenando en memoria...

ğŸ¤– IA: La inteligencia artificial es...

   â±ï¸ Tiempo: 3.2s
   âœ“ Confianza: 0.87
```

### Ver EstadÃ­sticas

```
ğŸ§‘ TÃº: /stats

ğŸ“Š ESTADÃSTICAS DEL SISTEMA

ğŸ’¬ ConversaciÃ³n:
  Total mensajes: 25
  Tasa aprobaciÃ³n: 96.0%

ğŸ§  Cerebro:
  Ticks: 50
  Episodios: 42
  Conceptos: 12
  Ciclos sueÃ±o: 1

ğŸ›¡ï¸ Gobernanza:
  AuditorÃ­as: 50
  Pass rate: 94.0%
```

### Forzar ConsolidaciÃ³n

```
ğŸ§‘ TÃº: /sleep

ğŸ’¤ Iniciando ciclo de sueÃ±o...

[FASE 1/4] NREM - ConsolidaciÃ³n...
[FASE 2/4] REM - Procesamiento creativo...
[FASE 3/4] ReorganizaciÃ³n...
[FASE 4/4] Homeostasis...

âœ… Completado
  50 episodios consolidados
  3 conceptos fusionados
  8 items podados
```

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Cambiar Modelo de Ollama

Editar `ollama_brain_interface.py`, lÃ­nea ~85:

```python
llm_config = LLMConfig(
    provider="ollama",
    base_url="http://localhost:11434",
    model="qwen2.5:3b",  # â† Cambiar aquÃ­
    temperature=0.7
)
```

### Ajustar ParÃ¡metros del Cerebro

Editar `ollama_brain_interface.py`, lÃ­nea ~95:

```python
brain_config = CompleteBrainConfig(
    dim_latent=64,           # TamaÃ±o estado (â†‘ = mÃ¡s memoria)
    max_episodes=500,        # MÃ¡x episodios (â†‘ = mÃ¡s historia)
    max_concepts=100,        # MÃ¡x conceptos (â†‘ = mÃ¡s generalizaciÃ³n)
    sleep_interval=50,       # Cada cuÃ¡ntos ticks dormir
    enable_learning=True,    # Aprendizaje continuo
    enable_homeostasis=True, # Auto-regulaciÃ³n
    enable_sleep=True        # ConsolidaciÃ³n nocturna
)
```

### Ajustar Gobernanza AMA-G

Editar `governance/amag_audit.py`, lÃ­nea ~40:

```python
thresholds=GovernanceThresholds(
    min_confidence=0.5,    # Confianza mÃ­nima (â†“ = mÃ¡s permisivo)
    max_surprise=3.0,      # Sorpresa mÃ¡xima (â†‘ = mÃ¡s tolerante)
    max_risk=0.7           # Riesgo mÃ¡ximo (â†‘ = mÃ¡s riesgoso)
)
```

---

## ğŸ“Š MÃ©tricas del Sistema

### MÃ©tricas en Tiempo Real

| MÃ©trica | DescripciÃ³n | Rango |
|---------|-------------|-------|
| **Confianza** | Seguridad de la decisiÃ³n | 0.0 - 1.0 |
| **Sorpresa** | Error de predicciÃ³n | 0.0 - âˆ |
| **AtenciÃ³n** | ConcentraciÃ³n del foco | 0.0 - 1.0 |
| **Episodios** | Experiencias almacenadas | 0 - max |
| **Conceptos** | Conocimiento abstracto | 0 - max |
| **WM Slots** | Memoria de trabajo activa | 0 - 7 |
| **Ticks** | Ciclos ejecutados | 0 - âˆ |

### Indicadores de Fase

- ğŸŸ¢ **Verde**: Fase activa y saludable
- ğŸŸ¡ **Amarillo**: Fase procesando
- ğŸ”´ **Rojo**: Fase con error
- âšª **Gris**: Fase inactiva

---

## ğŸ› Troubleshooting

### Problema: "Ollama no responde"

```bash
# Verificar que estÃ© ejecutÃ¡ndose
ollama serve

# En otra terminal:
curl http://localhost:11434/api/tags
```

### Problema: "Modelo no encontrado"

```bash
# Listar modelos
ollama list

# Descargar si falta
ollama pull gemma2:2b
```

### Problema: "Error de memoria"

- Usar modelos mÃ¡s pequeÃ±os (2B en vez de 7B)
- Reducir `max_episodes` y `max_concepts`
- Cerrar otras aplicaciones

### Problema: "tkinter no disponible"

```bash
# Linux
sudo apt-get install python3-tk

# macOS (con Homebrew)
brew install python-tk

# Windows: Reinstalar Python marcando "tcl/tk"
```

### Problema: "Respuestas siempre bloqueadas"

Ajustar umbrales de AMA-G (ver secciÃ³n ConfiguraciÃ³n Avanzada).

---

## ğŸ“ˆ Benchmarks de Rendimiento

### Tiempo de Respuesta (promedio)

| Modelo | RAM Usado | Latencia | Calidad |
|--------|-----------|----------|---------|
| gemma2:2b | 2.5 GB | 2-4s | â­â­â­ |
| qwen2.5:3b | 4 GB | 3-6s | â­â­â­â­ |
| llama3.2:3b | 4 GB | 3-6s | â­â­â­â­ |
| mistral:7b | 8 GB | 5-10s | â­â­â­â­â­ |

*Benchmarks en CPU i7-9700K, sin GPU*

### Overhead del Cerebro

- **Procesamiento adicional**: ~0.5-1s por mensaje
- **Memoria adicional**: ~100-200 MB
- **Beneficio**: Gobernanza completa + aprendizaje continuo

---

## ğŸ“ Casos de Uso

### 1. Asistente Personal Privado

```python
# Chat completamente privado
# Sin conexiÃ³n a internet
# Datos no salen de tu computadora
```

### 2. AnÃ¡lisis de Documentos Sensibles

```python
# Procesa documentos confidenciales
# Gobernanza garantiza no filtraciÃ³n
# ConsolidaciÃ³n en memoria local
```

### 3. Desarrollo de Software

```python
# Asistente de cÃ³digo
# Explica errores
# Genera documentaciÃ³n
```

### 4. EducaciÃ³n

```python
# Tutor personalizado
# Adapta explicaciones
# Aprende de tus preguntas
```

### 5. InvestigaciÃ³n

```python
# Analiza papers
# Sintetiza informaciÃ³n
# Memoria episÃ³dica de papers leÃ­dos
```

---

## ğŸ” Privacidad y Seguridad

### âœ… GarantÃ­as del Sistema

- **100% Local**: Nada sale de tu computadora
- **Sin telemetrÃ­a**: Cero tracking
- **Sin API keys**: No se necesitan credenciales externas
- **Datos encriptables**: Puedes encriptar el directorio completo
- **AuditorÃ­a AMA-G**: Cada interacciÃ³n es verificada

### ğŸ›¡ï¸ Gobernanza AMA-G

Cada mensaje pasa por:
1. **Intake**: ValidaciÃ³n de entrada
2. **Shadow Prompt**: Contexto de seguridad
3. **Output Validation**: VerificaciÃ³n de respuesta
4. **Intent Preservation**: IntenciÃ³n inmutable

**Tasa de bloqueo**: ~3-5% (solo respuestas problemÃ¡ticas)

---

## ğŸ“š Recursos Adicionales

### DocumentaciÃ³n

- `README.md` - Inicio rÃ¡pido
- `INSTALL.md` - InstalaciÃ³n detallada
- CÃ³digo con docstrings completos

### Enlaces

- **Ollama**: https://ollama.ai
- **Modelos**: https://ollama.ai/library
- **LM Studio**: https://lmstudio.ai

### Comunidad

- Reporta bugs creando un issue
- Comparte mejoras mediante pull requests
- Documenta tu experiencia

---

## ğŸ¯ Hoja de Ruta

### âœ… v1.0 - Sistema Completo (ACTUAL)

- FASE 1: PercepciÃ³n + DecisiÃ³n + Gobernanza
- FASE 2: Memoria completa
- FASE 3: Aprendizaje + Homeostasis
- IntegraciÃ³n Ollama/LM Studio
- CLI y GUI funcionales

### ğŸ”œ v1.1 - Mejoras de Rendimiento

- OptimizaciÃ³n de embeddings
- Cache de respuestas frecuentes
- Mejoras en consolidaciÃ³n

### ğŸ”œ v1.2 - Extensiones

- Plugins para herramientas externas
- API REST opcional
- Soporte multi-modelo

### ğŸ”œ v2.0 - Capacidades Avanzadas

- RAG (Retrieval-Augmented Generation)
- Fine-tuning de modelos
- Multi-agente

---

## ğŸ“ Changelog

### v1.0.0 (2025-01-03)

**Inicial Release**

- âœ… Sistema cerebral completo (3 fases)
- âœ… 18 mÃ³dulos funcionales
- âœ… IntegraciÃ³n con Ollama/LM Studio
- âœ… CLI interactiva
- âœ… GUI moderna
- âœ… Instalador automatizado
- âœ… DocumentaciÃ³n completa

---

## ğŸ¤ Contribuir

Este proyecto estÃ¡ abierto a contribuciones:

1. Fork del repositorio
2. Crea tu rama (`git checkout -b feature/amazing`)
3. Commit tus cambios (`git commit -m 'Add amazing feature'`)
4. Push a la rama (`git push origin feature/amazing`)
5. Abre un Pull Request

---

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto. Ãšsalo, modifÃ­calo y distribÃºyelo libremente.

---

## ğŸ™ Agradecimientos

- **Anthropic** por Claude (usado para desarrollo)
- **Ollama** por el motor de IA local
- **Comunidad open source** por librerÃ­as y herramientas

---

## ğŸ“ Soporte

Â¿Problemas? Â¿Preguntas?

1. Revisa la secciÃ³n **Troubleshooting**
2. Consulta la documentaciÃ³n completa
3. Crea un issue en el repositorio

---

**Â¡Disfruta de tu Cerebro Artificial! ğŸ§ ğŸš€**

VersiÃ³n: 1.0.0 | Fecha: 2025-01-03