# ğŸ§  AMA-Intent v3: Cerebro Local BiomimÃ©tico

Sistema de inteligencia artificial biomimÃ©tica diseÃ±ado para ejecutar procesos de manera local, funcionando como "Cortex" de Qodeia.com. 

Esta versiÃ³n v3 representa una refactorizaciÃ³n completa hacia una arquitectura minimalista y funcional, reduciendo las dependencias en un 84% y simplificando la estructura en un 80%.

## ğŸš€ Funcionalidad
- **Local**: Corre completamente en tu mÃ¡quina usando Ollama con Llama 3.1
- **Inteligente**: Memoria SQLite persistente con clasificaciÃ³n de intenciÃ³n automÃ¡tica
- **Conectado**: HTTP API FastHTML para integraciÃ³n con aplicaciones externas
- **Seguro**: EjecuciÃ³n localhost por defecto, sin exposiciÃ³n a internet

## ğŸ“ Estructura del Proyecto

```plaintext
proyecto-ama-intent/
â”œâ”€â”€ .env                  # (NO SUBIR A GITHUB) Claves y secretos
â”œâ”€â”€ .gitignore            # Importante: para ignorar .env y __pycache__
â”œâ”€â”€ README.md             # El manual de uso biomimÃ©tico
â”œâ”€â”€ requirements.txt      # Dependencias ligeras
â”œâ”€â”€ start.py              # El Ãºnico archivo que necesitas ejecutar
â”œâ”€â”€ data/                 # Donde vive tu memoria (SQLite)
â”‚   â””â”€â”€ ama_memory.db
â”œâ”€â”€ local_cortex/         # ğŸ§  LÃ“GICA PURA (Tu cerebro local)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ thought.py        # Procesa texto con Llama 3
â”‚   â””â”€â”€ memory.py         # Gestiona recuerdos en SQLite
â””â”€â”€ bridge/               # ğŸŒ‰ CONEXIÃ“N (Servidor Web)
    â”œâ”€â”€ __init__.py
    â””â”€â”€ server.py         # API FastHTML que habla con Qodeia.com
```

## ğŸ› ï¸ InstalaciÃ³n

### Requisitos Previos
1. Python 3.8 o superior
2. Ollama instalado y corriendo

### Pasos de InstalaciÃ³n

```bash
# 1. Clonar el repositorio
git clone https://github.com/dgr198213-ui/proyecto-ama-intent.git
cd proyecto-ama-intent

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Verificar que Ollama estÃ¡ corriendo
ollama serve  # En otra terminal

# 4. Descargar el modelo (si no lo tienes)
ollama pull llama3.1
```

## ğŸš€ Uso

### Iniciar el Sistema

```bash
python start.py
```

El sistema:
1. VerificarÃ¡ la carpeta `data/` (la crearÃ¡ si no existe)
2. VerificarÃ¡ que Ollama estÃ¡ disponible
3. IniciarÃ¡ el servidor en puerto 5001

### Acceder a la Interfaz

Abre tu navegador en: http://localhost:5001

### Acceder al Panel de AdministraciÃ³n

Para ver estadÃ­sticas y gestionar el sistema: http://localhost:5001/admin

### API Endpoints

**POST** `/api/synapse`

**ParÃ¡metros:**
- `input` (string): El texto a procesar

**Respuesta:**
```json
{
  "status": "success",
  "intent": "CHAT|CODIGO|ANALISIS",
  "confidence": 0.8,
  "response": "Respuesta generada por el modelo",
  "timestamp": "2026-01-23T16:35:20.123456"
}
```

**GET** `/api/memory/search?q={query}&limit={limit}`

Busca en la memoria del sistema.

**ParÃ¡metros:**
- `q` (string): TÃ©rmino de bÃºsqueda
- `limit` (int, opcional): NÃºmero mÃ¡ximo de resultados (default: 10)

**Respuesta:**
```json
{
  "status": "success",
  "query": "Python",
  "count": 3,
  "results": [
    {
      "timestamp": "2026-01-23T16:35:20.123456",
      "input": "What is Python?",
      "output": "Python is...",
      "intent": "CHAT"
    }
  ]
}
```

**GET** `/api/memory/stats`

Obtiene estadÃ­sticas de la memoria del sistema.

**Respuesta:**
```json
{
  "status": "success",
  "stats": {
    "total_interactions": 150,
    "by_intent": {
      "CHAT": 80,
      "CODIGO": 50,
      "ANALISIS": 20
    },
    "first_interaction": "2026-01-20T10:00:00",
    "last_interaction": "2026-01-23T16:35:20"
  }
}
```

**POST** `/api/memory/cleanup`

Limpia pensamientos antiguos de la memoria.

**ParÃ¡metros:**
- `days` (int, opcional): DÃ­as de antigÃ¼edad para limpiar (default: 30)

**Respuesta:**
```json
{
  "status": "success",
  "deleted_count": 25,
  "message": "Cleaned up 25 thoughts older than 30 days"
}
```

**GET** `/api/memory/by-intent/{intent}`

Obtiene pensamientos filtrados por tipo de intenciÃ³n.

**ParÃ¡metros:**
- `intent` (string): CHAT, CODIGO, o ANALISIS
- `limit` (int, opcional): NÃºmero mÃ¡ximo de resultados (default: 10)

**Respuesta:**
```json
{
  "status": "success",
  "intent": "CODIGO",
  "count": 10,
  "results": [
    {
      "timestamp": "2026-01-23T16:35:20",
      "input": "Write a function",
      "output": "def example(): ..."
    }
  ]
}
```

## ğŸ§  Arquitectura

### Local Cortex (Cerebro Local)
- **thought.py**: Procesa entradas usando Llama 3.1 a travÃ©s de Ollama
  - `LocalBrain.think()`: Genera respuestas contextualizadas
  - `LocalBrain.fast_classify()`: Clasifica el tipo de solicitud

- **memory.py**: Gestiona la memoria persistente
  - `init_db()`: Inicializa la base de datos SQLite
  - `save_thought()`: Guarda interacciones
  - `get_last_thoughts()`: Recupera contexto reciente

### Bridge (Puente HTTP)
- **server.py**: API FastHTML que conecta con el mundo exterior
  - Endpoint `/`: Interfaz de monitoreo
  - Endpoint `/api/synapse`: Procesa solicitudes

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno (.env)

```bash
# Server Configuration
HOST=127.0.0.1      # Server binding (localhost for security)
PORT=5001           # Server port
RELOAD=false        # Auto-reload (dev only)

# Ollama Configuration
OLLAMA_MODEL=llama3.1  # LLM model to use

# Memory Configuration
MEMORY_CONTEXT_LIMIT=5     # Number of recent thoughts to use as context
MEMORY_MAX_ENTRIES=1000    # Maximum entries before triggering cleanup
MEMORY_ARCHIVE_DAYS=30     # Archive thoughts older than N days

# Logging Configuration
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
```

## ğŸ“Š Base de Datos

El sistema usa SQLite para persistir interacciones:

**Tabla: interactions**
- `id`: INTEGER PRIMARY KEY
- `timestamp`: TEXT (ISO 8601)
- `input`: TEXT (entrada del usuario)
- `output`: TEXT (respuesta del sistema)
- `intent`: TEXT (clasificaciÃ³n: CODIGO, CHAT, ANALISIS)

## ğŸ› SoluciÃ³n de Problemas

### "Ollama no parece estar instalado"
AsegÃºrate de que Ollama estÃ¡ instalado y corriendo:
```bash
ollama serve
```

### "Error al conectar con Ollama"
Verifica que el modelo estÃ¡ descargado:
```bash
ollama pull llama3.1
```

### Puerto 5001 en uso
Cambia el puerto en `bridge/server.py` o usa la variable de entorno `PORT`:
```bash
PORT=5002 python start.py
```

### Error al importar mÃ³dulos
Si ves errores de importaciÃ³n, reinstala las dependencias:
```bash
pip install -r requirements.txt --force-reinstall
```

## ğŸ§ª Pruebas

Para verificar que todo funciona correctamente, ejecuta la suite de pruebas:

```bash
python test_ama_v3.py
```

Esta suite verifica:
- Estructura de directorios
- ImportaciÃ³n de mÃ³dulos
- Dependencias correctas
- Sintaxis de Python
- Funciones de memoria (init, save, retrieve)
- BÃºsqueda en memoria
- EstadÃ­sticas de memoria
- Limpieza de memoria
- Filtrado por intenciÃ³n

### Tests Actuales: 11/11 âœ…

## ğŸ“‹ Novedades en v3

### Cambios Principales desde v2
- âœ… **ReducciÃ³n de dependencias**: De 25+ paquetes a solo 4
- âœ… **SimplificaciÃ³n estructural**: De 15+ directorios a 3 mÃ³dulos core
- âœ… **CÃ³digo mÃ¡s limpio**: ~200 lÃ­neas vs ~10,000 lÃ­neas anteriores
- âœ… **Seguridad mejorada**: Localhost por defecto, context managers, subprocess seguro
- âœ… **Tests automatizados**: Suite completa con 11 tests (100% cobertura core)
- âœ… **API expandida**: 6 endpoints para gestiÃ³n completa del sistema
- âœ… **Panel de administraciÃ³n**: Dashboard web para monitoreo
- âœ… **BÃºsqueda en memoria**: Encuentra interacciones previas por palabras clave
- âœ… **GestiÃ³n automÃ¡tica**: Limpieza de memoria antigua
- âœ… **ConfiguraciÃ³n flexible**: Variables de entorno para personalizaciÃ³n

### Nuevas CaracterÃ­sticas en v3.1
- âœ… **Sistema de bÃºsqueda**: Busca en memoria histÃ³rica
- âœ… **EstadÃ­sticas avanzadas**: AnÃ¡lisis de uso por tipo de intenciÃ³n
- âœ… **Limpieza automÃ¡tica**: GestiÃ³n de memoria con archivado
- âœ… **Filtros por intenciÃ³n**: Recupera interacciones especÃ­ficas
- âœ… **Panel de admin**: Interfaz web para monitoreo del sistema
- âœ… **Mejor manejo de errores**: CÃ³digos HTTP apropiados y logging
- âœ… **Confidence scoring**: Las clasificaciones incluyen nivel de confianza

### CaracterÃ­sticas Eliminadas
- âŒ Dashboard web complejo
- âŒ Sistema de plugins v2
- âŒ AutenticaciÃ³n multi-usuario
- âŒ IntegraciÃ³n MiniMax
- âŒ Soporte Docker (por ahora)

Ver `REFACTORING_SUMMARY.md` para detalles completos.

## ğŸ¯ PrÃ³ximos Pasos

- IntegraciÃ³n con interfaces web externas
- Soporte para mÃºltiples modelos
- Sistema de plugins expandible
- AnÃ¡lisis de cÃ³digo avanzado

## ğŸ“ Soporte

Para reportar problemas o contribuir, abre un issue en el repositorio.

---

**AMA-Intent v3** - Sistema de Inteligencia BiomimÃ©tica Local
